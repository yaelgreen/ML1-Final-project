{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNTbNq1yXjyyXzXc8vvOLUb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yaelgreen/ML1-Final-project/blob/main/ML1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 1 - Initial dataset creation"
      ],
      "metadata": {
        "id": "87zx52clV5RZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yJ6dkwDV1sY"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, List\n",
        "\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from random import randint\n",
        "\n",
        "\n",
        "def random_indices(choose: int, out_of: int) -> List[int]:\n",
        "    return [randint(0, out_of) for i in range(0, choose)]\n",
        "\n",
        "\n",
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict\n",
        "\n",
        "\n",
        "def mapping(x):\n",
        "    return ((x / 225.0) * 2) - 1\n",
        "\n",
        "\n",
        "def download_and_extract_cifar_10_dataset(\n",
        "        url: str = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\") -> None:\n",
        "    filename = \"cifar-10-python.tar.gz\"\n",
        "\n",
        "    # Download the CIFAR 10 dataset\n",
        "    response = requests.get(url, stream=True)\n",
        "    if response.status_code == 200:\n",
        "        with open(filename, 'wb') as f:\n",
        "            f.write(response.raw.read())\n",
        "\n",
        "    # Extract the tar.gz file\n",
        "    import shutil\n",
        "    extract_path = \"cifar-10\"\n",
        "    shutil.unpack_archive(filename, extract_path)\n",
        "\n",
        "\n",
        "def create_training_and_validation_sets(training_size: str = 1000) -> \\\n",
        "        (Dict, Dict, Dict):\n",
        "    # load dataset\n",
        "    path = os.path.join(os.getcwd(), \"cifar-10\", \"cifar-10-batches-py\")\n",
        "    first_batch = unpickle(os.path.join(path, \"data_batch_1\"))\n",
        "    # choose random 1000 images\n",
        "    indices = random_indices(9999, training_size)\n",
        "    training_set = {\n",
        "        b'batch_label': first_batch[b'batch_label'],\n",
        "        b'labels': [first_batch[b'labels'][i] for i in indices],\n",
        "        b'data': np.take(first_batch[b'data'], indices, axis=0),\n",
        "        b'filenames': [first_batch[b'filenames'] for i in indices],\n",
        "    }\n",
        "    validation_set = unpickle(os.path.join(path, \"data_batch_2\"))\n",
        "    meta = unpickle(os.path.join(path, \"batches.meta\"))\n",
        "    return training_set, validation_set, meta\n",
        "\n",
        "\n",
        "def plot_image(data, meta, image_index=0):\n",
        "    # get image and RGB channels from dataset\n",
        "    image = data[b'data'][image_index, :]\n",
        "    image_r = image[0:1024].reshape(32, 32)\n",
        "    image_g = image[1024:2048].reshape(32, 32)\n",
        "    image_b = image[2048:].reshape(32, 32)\n",
        "    # plot image using RGB channefrom typing import Dict, List\n",
        "\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from random import randint\n",
        "\n",
        "\n",
        "def random_indices(choose: int, out_of: int) -> List[int]:\n",
        "â€¦convert_pixel_intensity(validation_set)\n",
        "\n",
        "\n",
        "\n",
        "ls\n",
        "    img = np.dstack((image_r, image_g, image_b))\n",
        "    title = meta[b'label_names'][data[b'labels'][image_index]]\n",
        "    return img, title\n",
        "    # plt.imshow(img)\n",
        "    # plt.title(meta[b'label_names'][data[b'labels'][image_index]])\n",
        "    # plt.show()\n",
        "\n",
        "\n",
        "def plot_random_images(data_set: Dict, meta: Dict, plt_title=\"plot\",\n",
        "                       number_of_images: int = 50) -> None:\n",
        "    # choose random 50 images\n",
        "    indices = random_indices(999, number_of_images)\n",
        "    # plot images\n",
        "    n_col = 10\n",
        "    n_row = int(number_of_images / n_col)\n",
        "    imgs = [plot_image(data_set, meta, image_index) for image_index in indices]\n",
        "    _, axs = plt.subplots(n_row, n_col, figsize=(32, 32))\n",
        "    axs = axs.flatten()\n",
        "    for img, ax in zip(imgs, axs):\n",
        "        ax.imshow(img[0])\n",
        "        ax.set_title(img[1])\n",
        "    plt.subplots_adjust(top=0.9)\n",
        "    plt.suptitle(plt_title)\n",
        "    plt.show()\n",
        "    plt.savefig(f\"{plt_title}.png\")\n",
        "\n",
        "\n",
        "def convert_pixel_intensity(data_set):\n",
        "    data_set[b'data'] = mapping(data_set[b'data'])\n",
        "\n",
        "\n",
        "download_and_extract_cifar_10_dataset()\n",
        "training_set, validation_set, meta = create_training_and_validation_sets()\n",
        "plot_random_images(training_set, meta, \"training_set_images\")\n",
        "plot_random_images(validation_set, meta, \"validation_set_images\")\n",
        "convert_pixel_intensity(training_set)\n",
        "convert_pixel_intensity(validation_set)"
      ]
    }
  ]
}